```
HDFS小文件问题

解决方法：
入库前:数据采集或标准入库前，将小文件进行合并大文件再上传入库
存储：Hadoop Archive归档->将多个小文件打包成一个HAR文件，减少对NN内存的使用
计算方面：将多个小文件进行切片生成以一个单独的切片或者少量的切片
其他:自己写一个MR程席将产生的小文件合并成一个大文件。如果是Hive或者Spark有mere功能自动帮助我
们合并。有小文件场景开启IVM重用;如果没有小文件，不要开启JM重用，因为会一直占用使用到的Task卡槽
直到任务完成才释放。JVM重用可以使得JM实例在同一个iob中重新使用N次，N的值可以在Hadoop的mapred
site.xml文件中进行配置。通常在10-20之间



flinkcdc
如果中间断了 后续会继续传还是从头传?
其实就是flink断点续传问题
(所有的断点续传都一样)，通过offset记录数据偏移量，然后存到文件里，下次从那个文件那里继续读，checkpoint以文件的形式存在hdfs中。
另一种是oos(向上存储)
指的是将数据从本地设备或较低层次的存储向云端的 OSS（Object Storage Service）等存储服务进行存储的过程。
因为有时候会因为网络波动或是文件过大导致传输中断，就得用断点续传了。提高文件传输的可靠性和效率，避免资源浪费。
```



```
完成dim层遇到的问题
1.报空指针
原因:未连接到hbase
2.存不进去数据
原因:名字没对应上。
	 流数据切割的有问题，格式对不上，存不进去
```